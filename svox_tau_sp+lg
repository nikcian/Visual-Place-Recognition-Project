# 6.1.2 Analisi della Selezione della Soglia: SVOX Sun Train (SP+LG)

Analogamente a quanto fatto per LoFTR, in questa sezione analizziamo il comportamento di **SuperPoint + LightGlue** sul dataset **SVOX Sun Train**. 
L'obiettivo è individuare la soglia di inlier $\tau$ che massimizzi l'F1-Score, garantendo il miglior compromesso tra il recupero delle query difficili e il risparmio di tempo.

![Trade-off Recall vs Saving SP+LG](grafici_tau/tau_svox_sun_train_sp+lg.png)
*Fig 6.2: Trade-off tra Recall@1 (Blu) e Risparmio Computazionale (Verde) per SuperPoint+LightGlue.*

### Analisi dei Dati e Tabella di Trade-off

La seguente tabella mostra l'andamento delle metriche al variare della soglia (step=5).

| Tau ($\tau$) | Recall@1 | Saving | F1-Score | Note |
| :--- | :--- | :--- | :--- | :--- |
| 0 | 18.12% | 93.32% | 0.6704 | |
| 5 | 21.49% | 80.50% | 0.6880 | |
| **10** | **33.01%** | **45.34%** | **0.7151** | ⭐ **BEST** |
| 15 | 36.80% | 33.97% | 0.7273 | |
| 20 | 38.48% | 30.80% | 0.7128 | |
| 25 | 38.90% | 28.82% | 0.7140 | |
| 30 | 39.47% | 26.97% | 0.7069 | |
| 35 | 39.61% | 26.44% | 0.7048 | |
| 40 | 39.89% | 26.04% | 0.6978 | |
| 45 | 39.89% | 25.78% | 0.6931 | |
| 50 | 40.03% | 25.38% | 0.6897 | |
| 55 | 40.73% | 24.72% | 0.6777 | |
| 60 | 40.87% | 24.59% | 0.6752 | |
| 65 | 41.29% | 23.93% | 0.6630 | |
| 70 | 41.99% | 23.13% | 0.6479 | |
| 75 | 42.13% | 22.21% | 0.6300 | |
| 80 | 42.56% | 20.62% | 0.5981 | |
| 85 | 43.12% | 19.04% | 0.5686 | |
| 90 | 44.24% | 17.45% | 0.5336 | |
| 95 | 44.66% | 16.52% | 0.5124 | |
| 100 | 45.08% | 15.07% | 0.4820 | |

> **Ottimo Matematico:** L'analisi fine (step=1) ha identificato il picco esatto dell'F1-Score a **$\tau = 12$**.

### Metodologia: Interpretazione per SuperPoint+LightGlue

A differenza di LoFTR, che produce corrispondenze dense, SuperPoint+LightGlue lavora su feature sparse. Questo influenza la distribuzione degli inlier e, di conseguenza, la scelta della soglia.

* **Soglie Molto Basse ($\tau < 5$):**
    Con $\tau=5$, il sistema ottiene un risparmio enorme (80%), ma la Recall@1 è ferma al 21%. Questo significa che molti match corretti hanno un numero di inlier superiore a 5, ma vengono ignorati o considerati "facili" erroneamente se ci affidiamo solo al retrieval globale.

* **La Zona Ottimale ($\tau \approx 12$):**
    Il punto di equilibrio matematico si trova a **$\tau=12$**.
    * A **$\tau=10$**, il risparmio è ancora molto elevato (**45.34%**), con una Recall che sale drasticamente al 33%.
    * Tra 10 e 15 inlier si trova il "gomito" della curva: superata questa soglia, la capacità del sistema di distinguere tra query facili e difficili basandosi solo sul numero di inlier diminuisce.
    * È interessante notare come SP+LG permetta un **risparmio computazionale maggiore** (circa 40-45% alla soglia ottima) rispetto a LoFTR (circa 33%), suggerendo che quando SP+LG trova un match con pochi inlier, è molto probabile che sia un vero negativo o un match difficile.

* **Soglie Alte ($\tau > 30$):**
    Oltre i 30 inlier, la curva di F1-Score inizia a scendere e il risparmio si appiattisce sotto il 27%. A differenza di LoFTR, dove la densità di punti permetteva soglie più alte, con SP+LG alzare troppo la soglia erode rapidamente il vantaggio dell'approccio adattivo, costringendo a calcoli inutili.

### Conclusione per SVOX Sun (SP+LG)

Selezioniamo **$\tau = 12$** come valore operativo.
Questa scelta è strategica: garantisce un **risparmio computazionale significativo (~40%)**, evitando il re-ranking su quasi la metà del dataset, pur mantenendo una Recall@1 competitiva e massimizzando l'F1-Score del classificatore *Easy/Hard*.